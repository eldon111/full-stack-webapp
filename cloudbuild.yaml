steps:
  # Print the branch name
  - id: 'branch-name'
    name: 'gcr.io/cloud-builders/git'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Building from branch: $BRANCH_NAME"

  # Install dependencies for all services
  - id: 'install-dependencies'
    name: 'node:22'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Installing dependencies for all services..."
        cd backend && npm ci; cd ..
        cd frontend && npm ci; cd ..

  # Build backend
  - id: 'build-backend'
    name: 'node:22'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Building backend..."
        cd backend
        npm run build

  # Build frontend for static hosting
  - id: 'build-frontend-static'
    name: 'node:22'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Building frontend for static hosting..."
        cd frontend
        # Set environment variables for runtime config
        export NODE_ENV=${_ENVIRONMENT}
        export VITE_REACT_APP_API_BASE_URL="${_BACKEND_URL}"
        # Build the static website
        npm run build

  # Create Cloud Function source archive
  - id: 'create-function-archive'
    name: 'debian:bullseye-slim'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Creating Cloud Function source archive..."
        # Install zip package
        apt-get update && apt-get install -y zip

        cd image-processor
        # Create a directory for the deployable
        mkdir -p /workspace/deployables/image-processor
        # Copy necessary files for deployment
        cp -r *.ts tsconfig.json package.json package-lock.json /workspace/deployables/image-processor/

        cd /workspace/deployables/image-processor
        zip -r ${_IMAGE_PROCESSOR_NAME}-${_ENVIRONMENT}-source.zip .
        mkdir -p /workspace/artifacts
        cp ${_IMAGE_PROCESSOR_NAME}-${_ENVIRONMENT}-source.zip /workspace/artifacts/

  # Create GCS bucket if it doesn't exist and upload function archive
  - id: 'create-bucket-and-upload'
    name: 'gcr.io/cloud-builders/gsutil'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Check if bucket exists, create it if it doesn't
        if ! gsutil ls -b gs://gcf-sources-${PROJECT_ID}-${_REGION} &>/dev/null; then
          echo "Creating bucket gs://gcf-sources-${PROJECT_ID}-${_REGION}..."
          gsutil mb -l ${_REGION} gs://gcf-sources-${PROJECT_ID}-${_REGION}
        else
          echo "Bucket gs://gcf-sources-${PROJECT_ID}-${_REGION} already exists."
        fi

        # Upload the function source archive
        echo "Uploading ${_IMAGE_PROCESSOR_NAME}-${_ENVIRONMENT}-source.zip to bucket..."
        gsutil cp /workspace/artifacts/${_IMAGE_PROCESSOR_NAME}-${_ENVIRONMENT}-source.zip gs://gcf-sources-${PROJECT_ID}-${_REGION}/${_IMAGE_PROCESSOR_NAME}-${_ENVIRONMENT}-source.zip

  # Build and push backend container
  - id: 'build-push-backend'
    name: 'gcr.io/cloud-builders/docker'
    args:
      - 'build'
      - '-t'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/cloud-run-source-deploy/${_BACKEND_SERVICE_NAME}-${_ENVIRONMENT}:${SHORT_SHA}'
      - '-t'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/cloud-run-source-deploy/${_BACKEND_SERVICE_NAME}-${_ENVIRONMENT}:latest'
      - './backend'

  # Deploy frontend static website to GCS bucket
  - id: 'deploy-frontend-static'
    name: 'gcr.io/cloud-builders/gsutil'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Deploying frontend static website to GCS bucket..."
        # Deploy to GCS bucket
        gsutil -m rsync -d -r frontend/dist gs://${_FRONTEND_STATIC_BUCKET}

        # Set Cache-Control metadata for static assets
        echo "Setting Cache-Control metadata for static assets..."
        gsutil -m setmeta -h "Cache-Control:public, max-age=31536000" gs://${_FRONTEND_STATIC_BUCKET}/assets/**

        # Set Cache-Control metadata for index.html and config.js (no caching)
        echo "Setting Cache-Control metadata for index.html and config.js..."
        gsutil setmeta -h "Cache-Control:no-cache, no-store, must-revalidate" gs://${_FRONTEND_STATIC_BUCKET}/index.html
        gsutil setmeta -h "Cache-Control:no-cache, no-store, must-revalidate" gs://${_FRONTEND_STATIC_BUCKET}/config.js

  # Push backend container
  - id: 'push-backend'
    name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/cloud-run-source-deploy/${_BACKEND_SERVICE_NAME}-${_ENVIRONMENT}:${SHORT_SHA}'

  # Push latest tags for backend
  - id: 'push-latest-tags'
    name: 'gcr.io/cloud-builders/docker'
    args:
      - 'push'
      - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/cloud-run-source-deploy/${_BACKEND_SERVICE_NAME}-${_ENVIRONMENT}:latest'

# Images to be pushed to the container registry
images:
  - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/cloud-run-source-deploy/${_BACKEND_SERVICE_NAME}-${_ENVIRONMENT}:${SHORT_SHA}'
  - '${_REGION}-docker.pkg.dev/${PROJECT_ID}/cloud-run-source-deploy/${_BACKEND_SERVICE_NAME}-${_ENVIRONMENT}:latest'

# Substitution variables
substitutions:
  _REGION: 'us-east4'
  _ENVIRONMENT: 'dev'
  _BACKEND_SERVICE_NAME: 'full-stack-webapp-backend'
  _FRONTEND_SERVICE_NAME: 'full-stack-webapp-frontend'
  _IMAGE_PROCESSOR_NAME: 'image-processor'
  _FRONTEND_STATIC_BUCKET: '${_FRONTEND_SERVICE_NAME}-${_ENVIRONMENT}-static'
  _BACKEND_URL: 'https://${_BACKEND_SERVICE_NAME}-${_ENVIRONMENT}-${PROJECT_NUMBER}.${_REGION}.run.app'

# Timeout for the build (30 minutes)
timeout: '1800s'

# Options
options:
  logging: CLOUD_LOGGING_ONLY
  machineType: 'E2_HIGHCPU_8'
